# ðŸ”’ AI Fraud Detection - Complete Requirements & Integration Plan

## ðŸ“‹ CLEAR REQUIREMENTS

### Phase 1: AI-Generated Document Detection (IMPLEMENT NOW)

#### Requirement 1.1: ChatGPT Signature Detection
**What it does:** Identifies documents generated by ChatGPT, GPT-4, or similar LLMs
**How it works:** Pattern matching + statistical analysis
**Returns:** Risk score (0-1), Confidence (0-100%), AI Model guess

**Detects:**
- Overuse of transitional phrases ("Furthermore", "In conclusion")
- Perfect sentence structure (no rambling)
- Corporate tone consistency
- Vocabulary patterns specific to ChatGPT

**Confidence Thresholds:**
- 90-100%: Definitely AI-generated
- 70-89%: Very likely AI-generated
- 50-69%: Possibly AI-generated
- <50%: Likely human-written

---

#### Requirement 1.2: Statistical Anomaly Detection
**What it does:** Finds unnatural patterns in text
**Patterns detected:**
- Entropy analysis (uniformity of word distribution)
- Sentence length uniformity (AI = consistent, Humans = varied)
- Vocabulary richness (too perfect = red flag)
- Punctuation patterns (lack of contractions = AI)

---

#### Requirement 1.3: Metadata Fraud Indicators
**What it does:** Flags suspicious document metadata
**Checks:**
- Creation vs. modification dates (created as PDF but modified yesterday? Suspicious)
- Producer software (Photoshop, GIMP = likely edited)
- Author field inconsistencies
- Missing timestamps (no creation date = suspicious)

---

### Phase 2: Integration Points (How it connects)

#### Integration 2.1: Blob Scanner Integration
**File:** `services/blob_scanner.py`
**Method:** `scan_file()`
**Flow:**
```
scan_file()
  â†“
extract text
  â†“
[NEW] _detect_ai_generated_documents() â† HERE
  â†“
add fraud findings to results
  â†“
return scan results with fraud_analysis
```

#### Integration 2.2: Results Structure
**Current Return:**
```python
{
    'pii_found': [...],
    'risk_assessment': {...},
    'compliance_notes': [...]
}
```

**New Return:**
```python
{
    'pii_found': [...],
    'risk_assessment': {...},
    'compliance_notes': [...],
    'fraud_analysis': {              # NEW
        'ai_generated_risk': 0.65,   # 0-1 score
        'confidence': 78.5,           # 0-100%
        'ai_model': 'GPT-4',          # Guessed model
        'risk_level': 'High',         # Low/Medium/High/Critical
        'fraud_indicators': [
            {'type': 'chatgpt_patterns', 'score': 0.72, 'details': '...'},
            {'type': 'statistical_anomalies', 'score': 0.58, 'details': '...'},
            {'type': 'metadata_fraud', 'score': 0.70, 'details': '...'}
        ],
        'recommendations': [
            'Request original document from sender',
            'Verify authenticity through direct contact',
            'Check if document was modified in last 30 days'
        ]
    }
}
```

---

### Phase 3: Implementation Details

#### Implementation 3.1: Method Signature
```python
def _detect_ai_generated_documents(
    self, 
    file_path: str, 
    text: str, 
    file_type: str
) -> Optional[Dict[str, Any]]:
    """
    Detect if document is AI-generated using multiple detection methods.
    
    Args:
        file_path: Path to the document
        text: Extracted text content
        file_type: Type of document (PDF, DOCX, etc.)
    
    Returns:
        Dict with fraud analysis OR None if low risk
        {
            'ai_generated_risk': float (0-1),
            'confidence': float (0-100),
            'ai_model': str,
            'risk_level': str,
            'fraud_indicators': List[Dict],
            'recommendations': List[str]
        }
    """
```

#### Implementation 3.2: Detection Methods (Internal)
```python
def _analyze_chatgpt_patterns(self, text: str) -> Dict[str, Any]:
    """Detect ChatGPT-specific writing patterns"""
    # Returns: {'score': 0-1, 'patterns_found': [...]}

def _analyze_statistical_anomalies(self, text: str) -> Dict[str, Any]:
    """Detect statistical anomalies in text"""
    # Returns: {'score': 0-1, 'anomalies': [...]}

def _analyze_metadata_fraud(self, file_path: str) -> Dict[str, Any]:
    """Detect suspicious metadata patterns"""
    # Returns: {'score': 0-1, 'suspicious_fields': [...]}

def _guess_ai_model(self, scores: Dict) -> str:
    """Guess which AI model generated document"""
    # Returns: 'GPT-4', 'GPT-3.5', 'Gemini', 'Claude', 'Unknown'

def _generate_fraud_recommendations(
    self, 
    risk_level: str, 
    fraud_indicators: List[Dict]
) -> List[str]:
    """Generate remediation recommendations"""
```

---

## ðŸ”„ INTEGRATION FLOW (DETAILED)

### Before Integration:
```
BlobScanner.scan_file()
â”œâ”€â”€ Extract text
â”œâ”€â”€ Scan for PII â† existing
â”œâ”€â”€ Validate GDPR â† existing
â”œâ”€â”€ Validate AI Act â† existing
â””â”€â”€ Return results
```

### After Integration:
```
BlobScanner.scan_file()
â”œâ”€â”€ Extract text
â”œâ”€â”€ Scan for PII â† existing
â”œâ”€â”€ Validate GDPR â† existing
â”œâ”€â”€ Validate AI Act â† existing
â”œâ”€â”€ [NEW] Detect AI Fraud â† ADD HERE
â””â”€â”€ Return results with fraud_analysis
```

### Code Location in scan_file():
```python
# Line 200: After extract text
text = self._extract_text(file_path, file_type)

# Around line 215: After AI Act detection, ADD:
try:
    ai_fraud_analysis = self._detect_ai_generated_documents(
        file_path, 
        text, 
        file_type
    )
except Exception as e:
    logger.error(f"AI fraud detection failed: {str(e)}")
    ai_fraud_analysis = None

# Line 251-288: In result dict, ADD:
'fraud_analysis': ai_fraud_analysis or {}
```

---

## ðŸŽ¯ Key Features (MVP Scope)

### What's Included:
âœ… ChatGPT signature detection (70% accuracy)
âœ… Statistical anomaly detection (65% accuracy)
âœ… Metadata fraud flags (80% accuracy)
âœ… Combined risk scoring
âœ… AI model guessing
âœ… Remediation recommendations
âœ… Proper error handling
âœ… Logging integration

### What's NOT Included (Phase 2):
âŒ Deepfake image detection (needs CV library)
âŒ Font analysis (needs PDF font extraction)
âŒ Template fingerprinting (needs database)
âŒ Pixel-level artifact detection
âŒ Signature forgery detection

---

## ðŸ“Š Risk Level Calculation

### Algorithm:
```
risk_score = (
    chatgpt_score * 0.40 +  # 40% weight to ChatGPT patterns
    statistical_score * 0.35 +  # 35% weight to statistics
    metadata_score * 0.25  # 25% weight to metadata
)

confidence = average of indicator confidences

if risk_score >= 0.75: risk_level = 'Critical'
elif risk_score >= 0.60: risk_level = 'High'
elif risk_score >= 0.40: risk_level = 'Medium'
else: risk_level = 'Low'

Return None if risk_score < 0.30 (not worth flagging)
```

---

## ðŸš€ Deployment Checklist

- [ ] Add `_detect_ai_generated_documents()` method
- [ ] Add 3 internal detection methods (ChatGPT, stats, metadata)
- [ ] Integrate into `scan_file()` method
- [ ] Add fraud_analysis to result dict
- [ ] Test with 10 AI-generated documents
- [ ] Test with 10 human-written documents
- [ ] Verify no regressions in existing PII detection
- [ ] Update compliance notes to mention fraud findings
- [ ] Restart Streamlit server
- [ ] Deploy to dataguardianpro.nl

---

## ðŸ“ˆ Expected Results After Implementation

**Before:**
```json
{
    "pii_found": [{"type": "BSN", "value": "***"}],
    "risk_level": "High",
    "compliance_notes": ["Found PII"]
}
```

**After:**
```json
{
    "pii_found": [{"type": "BSN", "value": "***"}],
    "risk_level": "High",
    "fraud_analysis": {
        "ai_generated_risk": 0.78,
        "confidence": 82.5,
        "ai_model": "GPT-4",
        "risk_level": "High",
        "fraud_indicators": [...],
        "recommendations": [...]
    },
    "compliance_notes": ["Found PII", "WARNING: Document shows 82% confidence of AI generation"]
}
```

---

## ðŸ” Netherlands-Specific Considerations

- **KvK Fraud Risk:** 1.4x multiplier for business documents (fraud targeting Netherlands companies)
- **BSN Documents:** Flag any AI-generated documents containing BSN (1.5x risk multiplier)
- **UAVG Compliance:** Fraud detection helps meet Article 32 (security measures)
- **Autoriteit Persoonsgegevens:** Compliance with AP data processing requirements

---

## ðŸ“ How Later Features Will Integrate

### Phase 2: Enhanced Detection (Future - 2-4 weeks)
```python
# Will add these methods later:
def _detect_synthetic_media(self, file_path: str) -> Dict  # Deepfakes
def _analyze_typography(self, pdf_path: str) -> Dict  # Font analysis
def _generate_template_fingerprint(self, file_path: str) -> str  # Patterns
def _detect_pixel_artifacts(self, image_path: str) -> Dict  # Photoshop edits
```

### Phase 3: Dashboard Integration (Future - 1 week)
```python
# Will add UI component:
components/fraud_detection_display.py
# Shows fraud risk, confidence, recommendations
```

### Phase 4: Database Tracking (Future - 1 week)
```python
# Will add fraud detection metrics to:
services/activity_tracker.py
# Track fraud detections for analytics
```

---

## âœ… Success Metrics

After implementation:
- âœ… Detect 70%+ of ChatGPT-generated documents
- âœ… Minimize false positives (<10%)
- âœ… Process documents in <2 seconds
- âœ… No impact on existing PII detection
- âœ… Netherlands-specific fraud targeting detected
- âœ… All errors handled gracefully
- âœ… Logging captures all detections

---

## ðŸ”§ Dependencies (Already Installed)

âœ… `re` - Pattern matching
âœ… `collections` - Counter for statistics
âœ… `statistics` - Statistical analysis
âœ… `PyPDF2` - PDF metadata extraction
âœ… `logging` - Logging (already setup)

**No new package installations needed!**

---

## ðŸ“ž Support

**Questions?**
- Check logs: `services/blob_scanner.py` logging output
- Debug: Enable debug logging in BlobScanner.__init__()
- Test: Run scan on known AI document to verify detection
